{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#paquetes \n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "#from random import shuffle\n",
    "import math\n",
    "import pandas as pd\n",
    "from scipy import optimize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PARA CADA RED: Me quedo con la componente gigante y me saco de encima el resto. Primero, voy a calcular, para todos los nodos de todas las redes, los siguientes parámetros: \n",
    "-degree centrality https://networkx.github.io/documentation/networkx-1.10/reference/algorithms.centrality.html \n",
    "-eigenvector centrality https://networkx.github.io/documentation/networkx-1.10/reference/generated/networkx.algorithms.centrality.eigenvector_centrality.html#networkx.algorithms.centrality.eigenvector_centrality -subgraph centrality https://networkx.github.io/documentation/networkx-1.10/reference/generated/networkx.algorithms.centrality.communicability_centrality.html#networkx.algorithms.centrality.communicability_centrality -shortest-path centrality https://networkx.github.io/documentation/networkx-1.10/reference/generated/networkx.algorithms.centrality.betweenness_centrality.html#networkx.algorithms.centrality.betweenness_centrality -current flow betweeness centrality https://networkx.github.io/documentation/networkx-1.10/reference/generated/networkx.algorithms.centrality.current_flow_betweenness_centrality.html#networkx.algorithms.centrality.current_flow_betweenness_centrality\n",
    "\n",
    "Ordeno mis nodos de mayor a menor para cada parametro. Voy sacando de a un nodo y me fijo de que tamaño queda el hub más grande. Eje x es fracción de nodos sacados, y eje y es la fracción de nodos en el hub más grande. Duda a contestar: y=nodos en hub/nodos total o y=nodos en hub/(nodos en red-nodos sacados)\n",
    "\n",
    "Después, para la tabla 3, veo el efecto de sacar todos (nro=E) mis nodos esenciales. Además, veo el efecto de sacar E nodos no esenciales (osea la misma cantidad que esenciales haya en la red) de manera random, pero respetando el grado. Por ejemplo, si tengo 10 esenciales de grado 8 y 16 esenciales de grado 7, tengo que sacar 10 noesenciales de grado 8 y 16 noesenciales de grado 7 etc... Eso se hace muchass veces de manera random y se calcula el valor medio y dispersion..\n",
    "\n",
    "Comentario: En realidad, lo formalmente bien seria ir redefiniendo todos mis parametros en cada iteración, pero como tardaria mil años, entonces lo hago \"cada tanto\". Saco ponele los 10 mas grandes y recalculo parametros en mi nueva componente gigante, etc etc Despues puedo comparar si realmente cambia o no, y cuánto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RED AP-MS\n",
    "ME QUEDO CON LA COMPONENTE GIGANTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ldata(archive):\n",
    "    f=open(archive)\n",
    "    data=[]\n",
    "    for line in f:\n",
    "        line=line.strip()\n",
    "        col=line.split()\n",
    "        data.append(col)\n",
    "    return data\n",
    "\n",
    "def grafo(datosRed):\n",
    "    G = nx.Graph()\n",
    "    for i in range(np.shape(datosRed)[0]):\n",
    "        G.add_edges_from([(datosRed[i][0],datosRed[i][1])])\n",
    "    return G "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "APMS = ldata('yeast_AP-MS.txt')\n",
    "GAPMS = grafo(APMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gc = max(nx.connected_component_subgraphs(GAPMS), key=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_degree=Gc.degree()\n",
    "degree=dict_degree.values()\n",
    "degreeordenado=sorted(set(degree),reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodosordenados=[]\n",
    "for j in degreeordenado:\n",
    "    for key,value in dict_degree.items():\n",
    "        if value==j:\n",
    "            nodosordenados.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38652"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodosordenados"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
